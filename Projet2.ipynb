{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROJET 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AddressOfEntryPoint</th>\n",
       "      <th>MajorLinkerVersion</th>\n",
       "      <th>MajorImageVersion</th>\n",
       "      <th>MajorOperatingSystemVersion</th>\n",
       "      <th>DllCharacteristics</th>\n",
       "      <th>SizeOfStackReserve</th>\n",
       "      <th>NumberOfSections</th>\n",
       "      <th>ResourceSize</th>\n",
       "      <th>legitimate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10407</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>33088</td>\n",
       "      <td>262144</td>\n",
       "      <td>4</td>\n",
       "      <td>952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5354</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>33088</td>\n",
       "      <td>262144</td>\n",
       "      <td>4</td>\n",
       "      <td>952</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>58807</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>33088</td>\n",
       "      <td>262144</td>\n",
       "      <td>4</td>\n",
       "      <td>136490</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>25166</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>33088</td>\n",
       "      <td>262144</td>\n",
       "      <td>4</td>\n",
       "      <td>1940</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>70387</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>33088</td>\n",
       "      <td>262144</td>\n",
       "      <td>4</td>\n",
       "      <td>83098</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137439</th>\n",
       "      <td>123291</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>33088</td>\n",
       "      <td>1048576</td>\n",
       "      <td>5</td>\n",
       "      <td>81654</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137440</th>\n",
       "      <td>40000</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>32768</td>\n",
       "      <td>1048576</td>\n",
       "      <td>8</td>\n",
       "      <td>67624</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137441</th>\n",
       "      <td>59610</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>33088</td>\n",
       "      <td>1048576</td>\n",
       "      <td>5</td>\n",
       "      <td>22648</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137442</th>\n",
       "      <td>51216</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1048576</td>\n",
       "      <td>8</td>\n",
       "      <td>2216</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>137443</th>\n",
       "      <td>22731</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>33088</td>\n",
       "      <td>1048576</td>\n",
       "      <td>5</td>\n",
       "      <td>318464</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>137444 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        AddressOfEntryPoint  MajorLinkerVersion  MajorImageVersion  \\\n",
       "0                     10407                   9                  6   \n",
       "1                      5354                   9                  6   \n",
       "2                     58807                   9                  6   \n",
       "3                     25166                   9                  6   \n",
       "4                     70387                   9                  6   \n",
       "...                     ...                 ...                ...   \n",
       "137439               123291                  11                  0   \n",
       "137440                40000                   2                  6   \n",
       "137441                59610                  10                  0   \n",
       "137442                51216                   2                  0   \n",
       "137443                22731                  11                  0   \n",
       "\n",
       "        MajorOperatingSystemVersion  DllCharacteristics  SizeOfStackReserve  \\\n",
       "0                                 6               33088              262144   \n",
       "1                                 6               33088              262144   \n",
       "2                                 6               33088              262144   \n",
       "3                                 6               33088              262144   \n",
       "4                                 6               33088              262144   \n",
       "...                             ...                 ...                 ...   \n",
       "137439                            5               33088             1048576   \n",
       "137440                            1               32768             1048576   \n",
       "137441                            5               33088             1048576   \n",
       "137442                            1                   0             1048576   \n",
       "137443                            5               33088             1048576   \n",
       "\n",
       "        NumberOfSections  ResourceSize  legitimate  \n",
       "0                      4           952           1  \n",
       "1                      4           952           1  \n",
       "2                      4        136490           1  \n",
       "3                      4          1940           1  \n",
       "4                      4         83098           1  \n",
       "...                  ...           ...         ...  \n",
       "137439                 5         81654           0  \n",
       "137440                 8         67624           0  \n",
       "137441                 5         22648           0  \n",
       "137442                 8          2216           0  \n",
       "137443                 5        318464           0  \n",
       "\n",
       "[137444 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv('malware.csv')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[['AddressOfEntryPoint','MajorLinkerVersion','MajorImageVersion','MajorOperatingSystemVersion','DllCharacteristics','SizeOfStackReserve','NumberOfSections','ResourceSize']] # on les choisit comme les feeture\n",
    "y = dataset['legitimate'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Diviser les données en ensembles d'entraînement et de test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instancier le modèle DecisionTreeClassifier sans spécifier les hyperparamètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model_arbre = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_arbre.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred1 = model_arbre.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur quadratique du model1: 0.01262323111062607\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Calculer l'erreur quadratique moyenne (MSE)\n",
    "mse1 = mean_squared_error(y_test, y_pred1)\n",
    "print(f'Erreur quadratique du model1: {mse1}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pour le model1:\n",
      "Accuracy: 0.987376768889374\n",
      "Precision: 0.9873955636223152\n",
      "Recall: 0.987376768889374\n",
      "F1 Score: 0.987384281497037\n",
      "Confusion Matrix:\n",
      "[[18995   191]\n",
      " [  156  8147]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "# Faire des prédictions sur l'ensemble de test\n",
    "\n",
    "# Évaluer la performance\n",
    "accuracy1 = accuracy_score(y_test, y_pred1)\n",
    "precision1 = precision_score(y_test, y_pred1, average='weighted')\n",
    "recall1 = recall_score(y_test, y_pred1, average='weighted')\n",
    "f1_1 = f1_score(y_test, y_pred1, average='weighted')\n",
    "conf_matrix1 = confusion_matrix(y_test, y_pred1)\n",
    "\n",
    "print('Pour le model1:')\n",
    "print(f'Accuracy: {accuracy1}')\n",
    "print(f'Precision: {precision1}')\n",
    "print(f'Recall: {recall1}')\n",
    "print(f'F1 Score: {f1_1}')\n",
    "print('Confusion Matrix:')\n",
    "print(conf_matrix1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définir la grille des hyperparamètres à explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "param_grid = { 'criterion': ['gini', 'entropy'], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4] }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_arbre1 = DecisionTreeClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Erreur quadratique du model1: 0.01262323111062607\n"
     ]
    }
   ],
   "source": [
    "model_arbre1.fit(X_train, y_train)\n",
    "y_pred2 = model_arbre1.predict(X_test)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# Calculer l'erreur quadratique moyenne (MSE)\n",
    "mse2 = mean_squared_error(y_test, y_pred2)\n",
    "print(f'Erreur quadratique du model1: {mse2}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appliquer Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]})</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={&#x27;criterion&#x27;: [&#x27;gini&#x27;, &#x27;entropy&#x27;],\n",
       "                         &#x27;max_depth&#x27;: [None, 10, 20, 30],\n",
       "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
       "                         &#x27;min_samples_split&#x27;: [2, 5, 10]})</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">DecisionTreeClassifier</label><div class=\"sk-toggleable__content\"><pre>DecisionTreeClassifier()</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=5, estimator=DecisionTreeClassifier(),\n",
       "             param_grid={'criterion': ['gini', 'entropy'],\n",
       "                         'max_depth': [None, 10, 20, 30],\n",
       "                         'min_samples_leaf': [1, 2, 4],\n",
       "                         'min_samples_split': [2, 5, 10]})"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "param_grid = { 'criterion': ['gini', 'entropy'], 'max_depth': [None, 10, 20, 30], 'min_samples_split': [2, 5, 10], 'min_samples_leaf': [1, 2, 4] }\n",
    "\n",
    "grid_search = GridSearchCV(estimator=model_arbre, param_grid=param_grid, cv=5)\n",
    "\n",
    "grid_search.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Afficher les meilleurs hyperparamètres après Grid Search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres après Grid Search : {'criterion': 'entropy', 'max_depth': None, 'min_samples_leaf': 1, 'min_samples_split': 2}\n"
     ]
    }
   ],
   "source": [
    "print(\"Meilleurs hyperparamètres après Grid Search :\", grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pipeline du Modèle 2 : Optimisation des Hyperparamètres pour la Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### I.   Sélection des Algorithmes de Classification:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voici 4 algorithmes de machine learning populaires pour la classification :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Random Forest \n",
    "- Décision Tree\n",
    "- KNeighbors\n",
    "- LogisticRegression,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### II. Voici les trois hyperparamètres les plus influents pour chaque algorithme sélectionné :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Random Forest :\n",
    " - n_estimators: Le nombre d'arbres dans la forêt. Plus ce nombre est élevé, plus le modèle peut capturer de complexité, mais cela peut aussi entraîner un surajustement si trop élevé.\n",
    " - max_depth: La profondeur maximale de chaque arbre dans la forêt. Contrôle la profondeur des arbres et donc la complexité du modèle.\n",
    " - min_samples_split: Le nombre minimum d'échantillons requis pour diviser un nœud interne. Cela peut aider à réguler la croissance des arbres et à prévenir le surajustement.\n",
    "2. Decision Tree :\n",
    " - max_depth: La profondeur maximale de l'arbre. Contrôle la complexité du modèle et peut aider à prévenir le surajustement.\n",
    " - min_samples_split: Le nombre minimum d'échantillons requis pour diviser un nœud interne. Comme pour Random Forest, cela peut aider à prévenir le surajustement en régulant la croissance de l'arbre.\n",
    " - criterion: Le critère utilisé pour mesurer la qualité de la division à chaque nœud. Par exemple, \"gini\" pour l'indice de Gini ou \"entropy\" pour l'entropie.\n",
    "3. KNeighbors :\n",
    " - n_neighbors: Le nombre de voisins à considérer lors de la prédiction. Cela affecte la souplesse du modèle.\n",
    " - weights: La méthode de pondération des voisins. Par exemple, \"uniform\" signifie que tous les voisins  contribuent également, tandis que \"distance\" signifie que les poids sont inverses à la distance.\n",
    " - metric: La mesure de distance utilisée pour calculer la similarité entre les échantillons. Par exemple, \"euclidean\", \"manhattan\", etc.\n",
    "4. Logistic Regression :\n",
    " - C: Le paramètre de régularisation, qui contrôle la force de la régularisation. Des valeurs plus élevées de C signifient moins de régularisation.\n",
    " - solver: L'algorithme utilisé pour optimiser les poids. Différents solveurs conviennent à différentes tailles de données et problèmes.\n",
    " - penalty: Le type de régularisation à appliquer. Par exemple, \"l1\" pour la régularisation L1 (Lasso) ou \"l2\" pour la régularisation L2 (Ridge)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### III. Optimisation par Grid Search, Random Search, ou Optuna "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Appliquez, pour chaque algorithme, l'une des méthodes d'optimisation avancées telles que Grid Search, Random Search, ou Optuna afin de déterminer les meilleures valeurs pour les hyperparamètres. Ces valeurs correspondent à celles qui rendent le modèle optimal en termes de performance. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Random Forest :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres pour Random Forest : {'max_depth': 20, 'min_samples_split': 2, 'n_estimators': 100}\n",
      "Précision du modèle Random Forest après optimisation : 0.9915966386554622\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Définition du modèle\n",
    "model = RandomForestClassifier()\n",
    "\n",
    "# Paramètres à rechercher\n",
    "parameters = {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]}\n",
    "\n",
    "# Grid Search\n",
    "clf = GridSearchCV(model, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs paramètres\n",
    "best_params = clf.best_params_\n",
    "print(\"Meilleurs hyperparamètres pour Random Forest :\", best_params)\n",
    "\n",
    "# Meilleur modèle\n",
    "best_model = clf.best_estimator_\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "# Calcul de la précision\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Précision du modèle Random Forest après optimisation :\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'model1' is your machine learning model\n",
    "pickle.dump(best_model, open(\"modelRanFor.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Decision Tree :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres pour Decision Tree : {'criterion': 'entropy', 'max_depth': 20, 'min_samples_split': 2}\n",
      "Précision du modèle Decision Tree après optimisation : 0.9879224417039543\n"
     ]
    }
   ],
   "source": [
    "# Définition du modèle\n",
    "model13 = DecisionTreeClassifier()\n",
    "\n",
    "# Paramètres à rechercher\n",
    "parameters = {'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10], 'criterion': ['gini', 'entropy']}\n",
    "\n",
    "# Grid Search\n",
    "clf = GridSearchCV(model13, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs paramètres\n",
    "best_params = clf.best_params_\n",
    "print(\"Meilleurs hyperparamètres pour Decision Tree :\", best_params)\n",
    "\n",
    "# Meilleur modèle\n",
    "best_model2 = clf.best_estimator_\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred13 = best_model2.predict(X_test)\n",
    "\n",
    "# Calcul de la précision\n",
    "accuracy = accuracy_score(y_test, y_pred13)\n",
    "print(\"Précision du modèle Decision Tree après optimisation :\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'model1' is your machine learning model\n",
    "pickle.dump(best_model2, open(\"modelDesTre.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. KNeighbors :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres pour KNeighbors : {'metric': 'manhattan', 'n_neighbors': 5, 'weights': 'distance'}\n",
      "Précision du modèle KNeighbors après optimisation : 0.9764996907854051\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "# Définition du modèle\n",
    "model14 = KNeighborsClassifier()\n",
    "\n",
    "# Paramètres à rechercher\n",
    "parameters = {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']}\n",
    "\n",
    "# Grid Search\n",
    "clf = GridSearchCV(model14, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs paramètres\n",
    "best_params = clf.best_params_\n",
    "print(\"Meilleurs hyperparamètres pour KNeighbors :\", best_params)\n",
    "\n",
    "# Meilleur modèle\n",
    "best_model3 = clf.best_estimator_\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred14 = best_model3.predict(X_test)\n",
    "\n",
    "# Calcul de la précision\n",
    "accuracy = accuracy_score(y_test, y_pred14)\n",
    "print(\"Précision du modèle KNeighbors après optimisation :\", accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'model1' is your machine learning model\n",
    "pickle.dump(best_model3, open(\"modelKNeig.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Logistic Regression :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\enock\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\enock\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"C:\\Users\\enock\\anaconda3\\lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "  File \"C:\\Users\\enock\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "  File \"C:\\Users\\enock\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "C:\\Users\\enock\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [0.92797963        nan 0.70566141 0.70505207 0.92789778        nan\n",
      " 0.70566141 0.70563412 0.92704288        nan 0.70566141 0.70563412]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Meilleurs hyperparamètres pour Logistic Regression : {'C': 0.1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Précision du modèle Logistic Regression après optimisation : 0.9287715086034414\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# Définition du modèle\n",
    "model15 = LogisticRegression()\n",
    "\n",
    "# Paramètres à rechercher\n",
    "parameters = {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs'], 'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Grid Search\n",
    "clf = GridSearchCV(model15, parameters, cv=5)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# Meilleurs paramètres\n",
    "best_params = clf.best_params_\n",
    "print(\"Meilleurs hyperparamètres pour Logistic Regression :\", best_params)\n",
    "\n",
    "# Meilleur modèle\n",
    "best_model3 = clf.best_estimator_\n",
    "\n",
    "# Prédiction sur l'ensemble de test\n",
    "y_pred15 = best_model3.predict(X_test)\n",
    "\n",
    "# Calcul de la précision\n",
    "accuracy = accuracy_score(y_test, y_pred15)\n",
    "print(\"Précision du modèle Logistic Regression après optimisation :\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Assuming 'model1' is your machine learning model\n",
    "pickle.dump(best_model3, open(\"modelLogRegr.pkl\", \"wb\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IV. Comparaison Avant et Après l'Optimisation :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Élaborez un tableau comparatif présentant, pour chaque algorithme, les résultats avant et après l'optimisation des hyperparamètres. Incluez des métriques de performance telles que la précision du modèle et la matrice de confusion. Conclusions et Recommandations :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yibtv/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py:378: FitFailedWarning: \n",
      "15 fits failed out of a total of 60.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/yibtv/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_validation.py\", line 686, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/yibtv/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 1162, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/Users/yibtv/anaconda3/lib/python3.11/site-packages/sklearn/linear_model/_logistic.py\", line 54, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/yibtv/anaconda3/lib/python3.11/site-packages/sklearn/model_selection/_search.py:952: UserWarning: One or more of the test scores are non-finite: [0.92817971        nan 0.70566141 0.70505207 0.92949843        nan\n",
      " 0.70566141 0.70505207 0.92883452        nan 0.70566141 0.70505207]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tableau Comparatif des Performances avant et après Optimisation des Hyperparamètres :\n",
      "             Modèle  Précision avant optimisation  Précision après optimisation         Matrice de Confusion\n",
      "      Random Forest                      0.991597                      0.991669  [[19063, 123], [106, 8197]]\n",
      "      Decision Tree                      0.987340                      0.987850  [[19002, 184], [150, 8153]]\n",
      "         KNeighbors                      0.970243                      0.976500  [[18812, 374], [272, 8031]]\n",
      "Logistic Regression                      0.699989                      0.928772 [[18708, 478], [1480, 6823]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Définition des modèles\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'KNeighbors': KNeighborsClassifier(),\n",
    "    'Logistic Regression': LogisticRegression()\n",
    "}\n",
    "\n",
    "# Paramètres à rechercher pour chaque modèle\n",
    "parameters = {\n",
    "    'Random Forest': {'n_estimators': [50, 100, 200], 'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10]},\n",
    "    'Decision Tree': {'max_depth': [None, 10, 20], 'min_samples_split': [2, 5, 10], 'criterion': ['gini', 'entropy']},\n",
    "    'KNeighbors': {'n_neighbors': [3, 5, 7], 'weights': ['uniform', 'distance'], 'metric': ['euclidean', 'manhattan']},\n",
    "    'Logistic Regression': {'C': [0.1, 1, 10], 'solver': ['liblinear', 'lbfgs'], 'penalty': ['l1', 'l2']}\n",
    "}\n",
    "\n",
    "results = []\n",
    "\n",
    "# Pour chaque modèle\n",
    "for name, model in models.items():\n",
    "    # Grid Search\n",
    "    clf = GridSearchCV(model, parameters[name], cv=5)\n",
    "    clf.fit(X_train, y_train)\n",
    "    best_params = clf.best_params_\n",
    "    best_model = clf.best_estimator_\n",
    "\n",
    "    # Prédiction sur l'ensemble de test\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Calcul de la précision du modèle\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Calcul de la matrice de confusion\n",
    "    confusion = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    # Stockage des résultats\n",
    "    results.append({'Modèle': name, 'Précision avant optimisation': model.fit(X_train, y_train).score(X_test, y_test),\n",
    "                    'Précision après optimisation': accuracy, 'Matrice de Confusion': confusion})\n",
    "\n",
    "# Création du dataframe\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Affichage du tableau comparatif\n",
    "print(\"\\nTableau Comparatif des Performances avant et après Optimisation des Hyperparamètres :\")\n",
    "print(results_df.to_string(index=False))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### V.  Analysez les résultats obtenus après l'optimisation et tirez des conclusions sur l'impact de cette démarche sur les performances des modèles."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après avoir analysé les résultats obtenus après l'optimisation des hyperparamètres, voici quelques conclusions tirées de l'impact de cette démarche sur les performances des modèles :\n",
    "- Amélioration de la précision : Dans la plupart des cas, l'optimisation des hyperparamètres a conduit à une amélioration significative de la précision des modèles par rapport aux performances avant l'optimisation. Cela indique que la sélection judicieuse des hyperparamètres peut aider à maximiser les performances des modèles.\n",
    "- Réduction de l'overfitting : L'optimisation des hyperparamètres a également permis de réduire le risque de surajustement dans certains cas. En trouvant les combinaisons optimales de paramètres, les modèles sont mieux régularisés et généralisent mieux sur de nouvelles données.\n",
    "- Choix du modèle : Les performances des modèles varient en fonction du type de problème et des données spécifiques. L'analyse des résultats peut aider à identifier le modèle le plus approprié pour la tâche de classification donnée. Par exemple, si l'interprétabilité est importante, un arbre de décision peut être préféré, tandis que si la précision est cruciale, un Random Forest ou un modèle de régression logistique peut être plus approprié."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VI. Pour la classification efficace des logiciels malveillants, voici quelques recommandations quant au choix final des modèles et de leurs hyperparamètres :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Random Forest :\n",
    "  - Recommandation : Le Random Forest est un choix solide pour la classification des logiciels malveillants en raison de sa capacité à gérer des ensembles de données complexes et à réduire le surajustement. Il peut capturer les relations non linéaires entre les caractéristiques des logiciels malveillants et fournir des prédictions robustes.\n",
    "  - Hyperparamètres recommandés : Une valeur élevée pour le nombre d'estimateurs peut être bénéfique pour améliorer la stabilité du modèle. De plus, une profondeur maximale des arbres plus grande et un nombre minimum d'échantillons requis pour diviser un nœud interne plus élevé peuvent aider à régulariser le modèle.\n",
    "2. Decision Tree :\n",
    "  - Recommandation : Les arbres de décision offrent une interprétabilité importante, ce qui peut être précieux pour comprendre les caractéristiques des logiciels malveillants. Cependant, ils peuvent être sensibles au surajustement, donc une attention particulière doit être accordée à la régularisation.\n",
    "  - Hyperparamètres recommandés : Limiter la profondeur maximale de l'arbre et augmenter le nombre minimum d'échantillons requis pour diviser un nœud interne peut aider à prévenir le surajustement.\n",
    "3. KNeighbors :\n",
    "  - Recommandation : KNeighbors peut être efficace pour la classification des logiciels malveillants en utilisant la similarité entre les logiciels malveillants et leurs voisins les plus proches. Cependant, cela peut être sensible à la présence de données bruitées ou mal étiquetées.\n",
    "  - Hyperparamètres recommandés : Une valeur plus élevée pour le nombre de voisins (n_neighbors) et une pondération basée sur la distance (weights='distance') peuvent améliorer la capacité du modèle à généraliser.\n",
    "4. Logistic Regression :\n",
    "  - Recommandation : La régression logistique peut être un choix simple et interprétable pour la classification des logiciels malveillants, en particulier si l'interprétabilité du modèle est une priorité. Elle peut également être efficace dans des cas où les classes sont linéairement séparables.\n",
    "  - Hyperparamètres recommandés : Une valeur plus petite pour le paramètre de régularisation C et l'utilisation de la régularisation L1 (penalty='l1') peuvent aider à prévenir le surajustement et à sélectionner des caractéristiques importantes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FIN"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
